class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = cutree(tree = hcl, k = k),
k = 3,
prob = TRUE)
# A nova observação com vetor de características dado no objeto X_new é alocada no mesmo grupo de Foz do Iguaçu
# quando o dendrograma é cortado para K=5 grupos e usa-se um (1 único) vizinho mais próximo para a predição.
# qual o grupo de Foz?
clus["Foz do Iguaçu"] # 1
# A nova observação com vetor de características dado no objeto X_new é alocada no mesmo grupo de Foz do Iguaçu
# quando o dendrograma é cortado para K=5 grupos e usa-se um (1 único) vizinho mais próximo para a predição.
# qual o grupo de Foz?
clus["Foz do Iguaçu"] # 1
class::knn(train = X,
test = matrix(X_new_teste, nrow = 1),
cl = cutree(tree = hcl, k = k),
k = 3,
prob = TRUE)
table(clus)
# Visualização com identificação dos grupos no dendrograma.
fviz_dend(hcl, k = k)
# Agrupamento hierárquico.
hcl <- hclust(dis, method = "complete")
?cutree
# Se for feito um corte na altura do dendrograma h = 6.5, então são criados 6 grupos. [TRUE]
# (análise visual)
clus <- cutree(tree = hcl, h = 6.5)
table(clus)
# e a nova observacao?
# Novos valores para terem a classe predita.
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = cutree(tree = hcl, k = k),
k = 3,
prob = TRUE)
# Novos valores para terem a classe predita.
X_new <- c(`Número de empresas atuantes` = 1.27,
`Pessoal ocupado` = 1.276,
`Pessoal ocupado assalariado` = 1.308,
`Salário médio mensal` = 1.143,
`Salários e outras remunerações` = 1.373,
`Unidades locais` = 1.267)
# e a nova observacao?
# Novos valores para terem a classe predita.
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = cutree(tree = hcl, k = k),
k = 3,
prob = TRUE)
?class::knn
clus <- cutree(tree = hcl, k = 5)
table(clus)
# A nova observação com vetor de características dado no objeto X_new é alocada no mesmo grupo de Foz do Iguaçu
# quando o dendrograma é cortado para K=5 grupos e usa-se um (1 único) vizinho mais próximo para a predição.
clus_b <- cutree(tree = hcl, k= 5)
clus_b["Foz do Iguaçu"] #
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = clus_b,
k = 1,
prob = TRUE)
X["Foz do Iguaçu", ]
# e a nova observacao?
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = clus_b,
k = 1,
prob = TRUE) #
# Com um corte na altura do dendrograma de h = 3, o grupo em que está Ponta Grossa fica com 14 observações.
clus_c <- cutree(tree = hcl, h = 3)
table(clus_c)
clus_c["Ponta Grossa"] # 2
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, K = 3)
clus_d["Curitiba"] # 9
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, K = 3)
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, K = 3)
# A nova observação com vetor de características dado no objeto X_new é alocada no mesmo grupo de Foz do Iguaçu
# quando o dendrograma é cortado para K=5 grupos e usa-se um (1 único) vizinho mais próximo para a predição.    [FALSE]
# qual o grupo de Foz?
clus_b <- cutree(tree = hcl, k= 5)
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, K= 3)
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, K= 4)
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, K= 5)
clus_b <- cutree(tree = hcl, k= 3)
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo.
clus_d <- cutree(tree = hcl, k= 3)
clus_d["Curitiba"] # 9
clus_d["Ponta Grossa"] # 9
clus_d["Curitiba"] # 9
table(clus_d)
# Com K=5, Maringá e Foz do Iguaçu ficaram no mesmo grupo.
clus_e <- cutree(tree = hcl, k= 5)
# Com K=5, Maringá e Foz do Iguaçu ficaram no mesmo grupo.
clus_e <- cutree(tree = hcl, k= 5)
clus_e[c("Maringá", "Foz do Iguaçu")] # 2
# Com K=4, Maringá e Pato Branco ficaram no mesmo grupo.
clus_f <- cutree(tree = hcl, k= 4)
clus_f[c("Maringá", "Pato Branco")] # 3 e 2
clus <- cutree(tree = hcl, h = 6.5)
table(clus)
clus_b <- cutree(tree = hcl, k= 5)
clus_b["Foz do Iguaçu"] # 2
# e a nova observacao?
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = clus_b,
k = 1,  # um único vizinho para predição
prob = TRUE) # 3
# A nova observação com vetor de características dado no objeto X_new é alocada no mesmo grupo de Foz do Iguaçu
# quando o dendrograma é cortado para K=5 grupos e usa-se um (1 único) vizinho mais próximo para a predição.    [FALSE]
# qual o grupo de Foz?
clus_b <- cutree(tree = hcl, k= 5)
clus_b["Foz do Iguaçu"] # 2
# e a nova observacao?
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = clus_b,
k = 1,  # um único vizinho para predição
prob = TRUE) # 3
# e a nova observacao?
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = clus_b,
k = 1,  # um único vizinho para predição
prob = FALSE) # 3
# e a nova observacao?
class::knn(train = X,
test = matrix(X_new, nrow = 1),
cl = clus_b,
k = 1,  # um único vizinho para predição
prob = TRUE) # 3
# Com um corte na altura do dendrograma de h = 3, o grupo em que está Ponta Grossa fica com 14 observações. [TRUE]
clus_c <- cutree(tree = hcl, h = 3)
clus_c["Ponta Grossa"] # 9
table(clus_c)
# Com K=3, Curitiba ficou em um grupo isolado sendo a única observação do grupo. [FALSE]
clus_d <- cutree(tree = hcl, k= 3)
clus_d["Curitiba"] # 2
table(clus_d)
clus_d[clus_d==1]
clus_d[clus_d==3]
table(clus_d)
# Com K=5, Maringá e Foz do Iguaçu ficaram no mesmo grupo. [FALSE]
clus_e <- cutree(tree = hcl, k= 5)
clus_e[c("Maringá", "Foz do Iguaçu")] # 3 e 2
# Com K=5, Maringá e Foz do Iguaçu ficaram no mesmo grupo. [FALSE]
clus_e <- cutree(tree = hcl, k= 5)
clus_e[c("Maringá", "Foz do Iguaçu")] # 3 e 2
# Com K=4, Maringá e Pato Branco ficaram no mesmo grupo. [TRUE]
clus_f <- cutree(tree = hcl, k= 4)
clus_f[c("Maringá", "Pato Branco")] # 2 e 2
getwd
getwd()
choose.files
choose.files?
?choose.files
?read.csv
dados <- read.csv(choose.files(), header = T, sep=";")
dados <- read.csv(choose.files(), header = T, sep=";")
View(dados)
?View
View(dados)
nrow(dados)
# olhar a estrutura vai ser importante para o processo de discretização
str(dados)
?lapply()
type(dados)
typeof(dados)
class(dados)
dados[,2:5]
str(dados)
# transforming into factor
dados[,2:5] <- lapply(dados[,2:5])
?factor()
# transforming into factor
dados[,2:5] <- lapply(dados[,2:5], factor)
str(dados)
dados <- read.csv(choose.files(), header = T, sep=";")
# it'll be important to know the structure due to the discretization process
str(dados)
# transforming into factor
dados[,2:4] <- lapply(dados[,2:4], factor)
str(dados)
?as.numeric
dados$area <- as.numeric(dados$area)
dados$value <- as.numeric(dados$value)
str(dados)
dados$value <- as.numeric(dados$value)
# checking how many NAs were introduced
is.na(dados)
?apply()
# checking how many NAs were introduced
apply(is.na(dados), 2, sum()) # 2 means summing by columns
# checking how many NAs were introduced
apply(is.na(dados), 2, sum) # 2 means summing by columns
?na.omit()
# removing NAs
dados <- na.omit(dados)
# checking how many NAs were introduced
apply(is.na(dados), 2, sum) # 2 means summing by columns
nrow(dados)
# ---------------------------- #
# ---------  EDA  ------------ #
# ---------------------------- #
hist(dados$value)
summary(dados$value)
# Discretizing
require("bnlearn")
require("qgraph")
install.packages("qgraph")
require("qgraph")
names(dados)
#dados_d=dados
dados_d <- bnlearn::discretize(dados[,c(1,5)],
method='hartemink', breaks=3) # these are the default params
dados_d
dados_d=dados
dados_d[,c(1,5)] <- bnlearn::discretize(dados[,c(1,5)],
method='hartemink', breaks=3) # these are the default params
dados_d
str(dados_d)
# checking how are the categories now
boxplot(dados$value~dados_d$value)
table(dados_d[,5])
boxplot(dados$area~dados_d$area)
table(dados$area)
table(dados_d$area)
table(dados_d$valor)
table(dados_d$value)
# strong linear correlation between area and value
plot(dados$area, dados$value)
table(dados_d$area, dados_d$value)
levels(dados_d$area)
abline(v = c(123), col='red')
abline(v = c(123, 180), col='red')
levels(dados_d$value)
# ploting lines
abline(v = c(123, 180), col='red')
abline(h = c(1400000, 1850000), col='red')
# strong linear correlation between area and value, so let's check the correlation in continuous and discrete cases:
plot(dados$area, dados$value)
# ploting lines
abline(v = c(123, 180), h = c(1400000, 1850000), col='red')
?hc()
# creating the model (hill climb):
mod_hc <- hc(dados_d, score="k2")
# exploring the structure with qgraph
qgraph(mod_hc)
require("qgraph")
install.packages("installr")
library(installr)
updateR()
library(bnlearn)
dag
# creating the DAG with one node for each variable in the survey. No archs at this point
dag <- empty.graph(nodes = c("A", "S", "E", "O", "R", "T"))
dag
# Age and Sex have a direct influence on Education:
dag <- set.arc(dag, from = "A", to = "E")
dag <- set.arc(dag, from = "S", to = "E")
dag <- set.arc(dag, from = "E", to = "O")
dag <- set.arc(dag, from = "E", to = "R")
dag <- set.arc(dag, from = "O", to = "T")
dag <- set.arc(dag, from = "R", to = "T")
dab
dag
modelstring(dag)
# MANIPULATING ARCHS
# with bnlearn we can manipulate the arcs
# checking the nodes
nodes(dag)
arcs(dag)
arc.set
dag2 <- empty.graph(nodes = c("A", "S", "E", "O", "R", "T"))
arc.set <- matrix(c("A", "E",
"S", "E",
"E", "O",
"E", "R",
"O", "T",
"R", "T"),
byrow = TRUE, ncol = 2,
dimnames = list(NULL, c("from", "to")))
arc.set
dag2
arcs(dag2) <- arc.set
dag2
# comparing two dags
all.equal(dag, dag2)
all.equal?
?all.equal
?all.equal
# if we try to insert a cycle it will prevent that, by causing an error
set.arc(dag, from = "T", to = "E")
# if we try to insert a cycle it will prevent that, by causing an error
try(set.arc(dag, from = "T", to = "E"))
# if we try to insert a cycle it will prevent that, by causing an error
set.arc(dag, from = "T", to = "E")
# creating the LEVELS of the variables:
A.lv <- c("young", "adult", "old")
S.lv <- c("M", "F")
E.lv <- c("high", "uni")
O.lv <- c("emp", "self")
R.lv <- c("small", "big")
T.lv <- c("car", "train", "other")
T.lv
# PROBABILITIES
# creating the probabilities tables
# Age and Sex are modelled by simple, unidimensional probability tables (they have no parent)
A.prob <- array(c(0.30, 0.50, 0.20), dim = 3,
dimnames = list(A = A.lv))
A.prob
A
A
A.prob
S.prob <- array(c(0.60, 0.40), dim = 2,
+ dimnames = list(S = S.lv))
S.prob <- array(c(0.60, 0.40), dim = 2,
dimnames = list(S = S.lv))
S.prob <- array(c(0.60, 0.40), dim = 2,
dimnames = list(S = S.lv))
S.prob
# Ocupation and Residence, which depend on Education, are modelled by
# two-dimensional conditional probability tables.
O.prob <- array(c(0.96, 0.04, 0.92, 0.08), dim = c(2, 2),
dimnames = list(O = O.lv, E = E.lv))
O.prob
R.prob <- array(c(0.25, 0.75, 0.20, 0.80), dim = c(2, 2),
dimnames = list(R = R.lv, E = E.lv))
R.prob
E.prob <- array(c(0.75, 0.25, 0.72, 0.28, 0.88, 0.12, 0.64,
0.36, 0.70, 0.30, 0.90, 0.10), dim = c(2, 3, 2),
dimnames = list(E = E.lv, A = A.lv, S = S.lv))
T.prob <- array(c(0.48, 0.42, 0.10, 0.56, 0.36, 0.08, 0.58,
0.24, 0.18, 0.70, 0.21, 0.09), dim = c(3, 2, 2),
dimnames = list(T = T.lv, O = O.lv, R = R.lv))
E.prob
T.prob
# recreating the DAG with the string for didactic purposes
# the string is the same of the factorized global distribution
dag3 <- model2network("[A][S][E|A:S][O|E][R|E][T|O:R]")
all.equal(dag, dag3)
# combining the structure of the DAG with the local distributions (which are in a list)
cpt <- list(A = A.prob, S = S.prob, E = E.prob, O = O.prob,
R = R.prob, T = T.prob)
cpt
?custom.fit
# fit the parameters of a BN:
bn <- custom.fit(dag, cpt)
bn
nparams(bn)
# bn.fit
type(bn)
# bn.fit
typeof(bn)
# bn.fit
class(bn)
# they can be used as if they were of class bn:
arcs(bn)
nodes(bn)
parents(bn)
bn$R
# the conditional probability tables can be printed from the bn.fit object
bn$R
#
coef(bn$R)
?coef
# just typing the bn.fit object causes all the prob tables to be printed
bn
?prop.table
getwd()
# ESTIMATING the local distributions
# while custom.fit() constructs the BN using a set of custom parameters specified by the user,
# bn.fit() estimates the parameters from data. Both return a bn.fit object
# "method" attribute determines which estimator to use. mle="maximum likelihood estimator"
setwd("C:/dev/bayesian-nets/book-scutari")
getwd()
survey <- read.table("survey.txt", header = TRUE)
head(survey)
bn.mle <- bn.fit(dag, data = survey, method = "mle")
str(survey)
# converting columns to factor
survey$A
# converting columns to factor
survey$A <- as.factor(survey$A)
str(survey)
survey$R <- as.factor(survey$R)
survey$E <- as.factor(survey$E)
survey$O <- as.factor(survey$O)
survey$S <- as.factor(survey$S)
survey$T <- as.factor(survey$T)
str(survey)
# mle = maximum likelihood estimator
bn.mle <- bn.fit(dag, data = survey, method = "mle")
View(bn.mle)
str(bn.mle)
bn$A
bn.mle$A
bn.mle$R
# we can also estimate the probs with R's prob.table, which is also based on frequency
# so we get the same results as the bn.fit with mle
prop.table(table(survey[, c("O", "E")]), margin = 2)
survey[, c("O", "E")]
table(survey[, c("O", "E")])
# we can also estimate the probs with R's prob.table, which is also based on frequency
# so we get the same results as the bn.fit with mle
prop.table(table(survey[, c("E", "O")]), margin = 2)
# we can also estimate the probs with R's prob.table, which is also based on frequency
# so we get the same results as the bn.fit with mle
prop.table(table(survey[, c("O", "E")]), margin = 2)
bn.mle$O
# estimating conditional probs in a Bayesian setting
bn.bayes <- bn.fit(dag, data = survey, method = "bayes",
iss = 10)
# iss = imaginary sample size
bn.bayes$O
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 20)
bn.bayes$O
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 200)
bn.bayes$O
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 2000)
bn.bayes$O
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 20000)
bn.bayes$O
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 200000)
bn.bayes$O
bn.bayes <- bn.fit(dag, data = survey, method = "bayes", iss = 20)
bn.bayes$O
# mutual information (mi) or "G2" test
ci.test("T", "E", c("O", "R"), test = "mi", data = survey)
# Pearson’s X2 test:
ci.test("T", "E", c("O", "R"), test = "x2", data = survey)
ci.test("T", "O", "R", test = "x2", data = survey)
arc.strength(dag, data = survey, criterion = "x2")
?arc.strengh
arc.strength
?arc.strength
score(dag, data = survey, type = "bic")
score(dag, data = survey, type = "bde", iss = 10)
# BDe needs iss parameter (imaginary sample size) since it uses a prior prob
# For small values of iss or large observed samples, log BDe and BIC scores yield similar values.
score(dag, data = survey, type = "bde", iss = 1)
# BDe needs iss parameter (imaginary sample size) since it uses a prior prob
# For small values of iss or large observed samples, log BDe and BIC scores yield similar values.
score(dag, data = survey, type = "bde", iss = 0.5)
# BDe needs iss parameter (imaginary sample size) since it uses a prior prob
# For small values of iss or large observed samples, log BDe and BIC scores yield similar values.
score(dag, data = survey, type = "bde", iss = 0.9)
# BDe needs iss parameter (imaginary sample size) since it uses a prior prob
# For small values of iss or large observed samples, log BDe and BIC scores yield similar values.
score(dag, data = survey, type = "bde", iss = 01)
# BDe needs iss parameter (imaginary sample size) since it uses a prior prob
# For small values of iss or large observed samples, log BDe and BIC scores yield similar values.
score(dag, data = survey, type = "bde", iss = 1)
# using these scores, we can remove or add an arc and then check whether this change
# improved or decreased the score of the DAG
dag4 <- set.arc(dag, from = "E", to = "T")
nparams(dag4, survey)
score(dag4, data = survey, type = "bic")
# scoring the DAG with both BIC and BDe
score(dag, data = survey, type = "bic")
# generate a DAG at random and compare it with the previous DAG
rnd <- random.graph(nodes = c("A", "S", "E", "O", "R", "T"))
modelstring(rnd)
score(rnd, data = survey, type = "bic")
# estimating with hc() (hill-climbing)
learned <- hc(survey)
modelstring(learned)
score(learned, data = survey, type = "bic")
# testing with "bde" score
learned2 <- hc(survey, score = "bde")
modelstring(learned)
score(learned, data = survey, type = "bic")
score(learned, data = survey, type = "bde")
arc.strength(learned, data = survey, criterion = "bic")
###############################
# USING THE BAYESIAN NETWORK
##############################
# checking if S and R are d-separated
dsep(dag, x = "S", y = "R")
dsep(dag, x = "O", y = "R")
# S is associated with R because E is influenced by S and R is influenced by E
# path function shows there is a path from S to R
path(dag, from = "S", to = "R")
# S is associated with R because E is influenced by S and R is influenced by E
# path function shows there is a path from S to R
path(dag, from = "S", to = "R")
# S is associated with R because E is influenced by S and R is influenced by E
# path function shows there is a path from S to R
path.exists(dag, from = "S", to = "R")
dsep(dag, x = "S", y = "R", z = "E")
# if we condition on E, that path is blocked and S and R become independent
dsep(dag, x = "S", y = "R", z = "E")
?COMPILE
# USING THE CONDITION PROBABILITY TABLES
library(gRain)
# building the junction tree:
junction <- compile(as.grain(bn))
install.packages("RBGL")
# building the junction tree:
junction <- compile(as.grain(bn))
#install.packages("RBGL")
library(RBGL)
#install.packages("RBGL")
library("RBGL")
install.packages("RBGL")
BiocManager::install("RBGL")
